{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNv29WPr2hSjlJeI/CBi3nZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wileyw/DeepLearningDemos/blob/master/RL_from_human_feedback/RL_from_human_feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tatsu-lab/stanford_alpaca.git"
      ],
      "metadata": {
        "id": "Mcfmw95BVnkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%python3 -m pip install -r stanford_alpaca/requirements.txt"
      ],
      "metadata": {
        "id": "6VQWwYyBWGQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "ghX-6yKfWoGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd transformers"
      ],
      "metadata": {
        "id": "E8iEJocrWtyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9OAmFjMQNYF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "0G3yWBv_XgrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls stanford_alpaca/\n"
      ],
      "metadata": {
        "id": "41QrI6gNQQLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd transformers"
      ],
      "metadata": {
        "id": "DIjJ0b8WYy5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/transformers/models/llama/convert_llama_weights_to_hf.py \\\n",
        "    --input_dir /path/to/downloaded/llama/weights \\\n",
        "    --model_size 7B \\\n",
        "    --output_dir /output/path"
      ],
      "metadata": {
        "id": "Y4hVfUwoZDJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stanford_alpaca"
      ],
      "metadata": {
        "id": "HXpP37VVXmd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir output"
      ],
      "metadata": {
        "id": "Rph7DmASX4wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!torchrun --nproc_per_node=1 --master_port=<your_random_port> train.py \\\n",
        "    --model_name_or_path <your_path_to_hf_converted_llama_ckpt_and_tokenizer> \\\n",
        "    --data_path ./alpaca_data.json \\\n",
        "    --bf16 True \\\n",
        "    --output_dir /content/stanford_alpaca \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 8 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 2000 \\\n",
        "    --save_total_limit 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --fsdp \"full_shard auto_wrap\" \\\n",
        "    --fsdp_transformer_layer_cls_to_wrap 'LLaMADecoderLayer' \\\n",
        "    --tf32 True"
      ],
      "metadata": {
        "id": "U5NIKbFvXpPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}