{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_network.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/wileyw/DeepLearningDemos/blob/master/SiameseNetwork/siamese_network.ipynb",
      "authorship_tag": "ABX9TyNGi/KzCla05WbLxc519Nzd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wileyw/DeepLearningDemos/blob/master/SiameseNetwork/twin_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js4124anRYJO"
      },
      "source": [
        "# Twin Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwjtWmOdRQeR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icUAqOYASn_k"
      },
      "source": [
        "# !unzip drive/MyDrive/fruits-360.zip -d drive/MyDrive\n",
        "# https://towardsdatascience.com/siamese-networks-line-by-line-explanation-for-beginners-55b8be1d2fc6"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-aRHmZaXYkm"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_dbmTg1XdUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444cf9ee-a068-4576-9663-f7800e05ef53"
      },
      "source": [
        "base_dir = r'/content/drive/MyDrive/fruits-360/Training/'\n",
        "train_test_split = 0.7\n",
        "no_of_files_in_each_class = 10\n",
        "\n",
        "#Read all the folders in the directory\n",
        "folder_list = os.listdir(base_dir)\n",
        "print( len(folder_list), \"categories found in the dataset\")\n",
        "\n",
        "#Declare training array\n",
        "cat_list = []\n",
        "x = []\n",
        "y = []\n",
        "y_label = 0\n",
        "\n",
        "#Using just no_of_files_in_each_class images per category\n",
        "for folder_name in folder_list:\n",
        "    files_list = os.listdir(os.path.join(base_dir, folder_name))\n",
        "    if len(files_list) < no_of_files_in_each_class:\n",
        "      print(f\"skipping {folder_name}\")\n",
        "      continue\n",
        "    temp=[]\n",
        "    for file_name in files_list[:no_of_files_in_each_class]:\n",
        "        temp.append(len(x))\n",
        "        x.append(np.asarray(Image.open(os.path.join(base_dir, folder_name, file_name)).convert('RGB').resize((100, 100))))\n",
        "        y.append(y_label)\n",
        "    y_label+=1\n",
        "    cat_list.append(temp)\n",
        "\n",
        "cat_list = np.asarray(cat_list)\n",
        "x = np.asarray(x)/255.0\n",
        "y = np.asarray(y)\n",
        "print('X, Y shape',x.shape, y.shape, cat_list.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131 categories found in the dataset\n",
            "X, Y shape (1310, 100, 100, 3) (1310,) (131, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfdur2NiUyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1bf59c-b8c6-4440-cbf4-e3929042b237"
      },
      "source": [
        "# Adapt x input dimension to PyTorch format.\n",
        "x = x.transpose(0, 3, 1, 2)\n",
        "print('X, Y shape',x.shape, y.shape, cat_list.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X, Y shape (1310, 3, 100, 100) (1310,) (131, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhS_zspMYXyb"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIRD6DN3YPyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58bc3d9f-3fbf-4eb9-bb0d-f4c648c90a76"
      },
      "source": [
        "train_size = int(len(folder_list)*train_test_split)\n",
        "test_size = len(folder_list) - train_size\n",
        "print(train_size, 'classes for training and', test_size, ' classes for testing')\n",
        "\n",
        "train_files = train_size * no_of_files_in_each_class\n",
        "\n",
        "#Training Split\n",
        "x_train = x[:train_files]\n",
        "y_train = y[:train_files]\n",
        "cat_train = cat_list[:train_size]\n",
        "\n",
        "#Validation Split\n",
        "x_val = x[train_files:]\n",
        "y_val = y[train_files:]\n",
        "cat_test = cat_list[train_size:]\n",
        "\n",
        "print('X&Y shape of training data :',x_train.shape, 'and', y_train.shape, cat_train.shape)\n",
        "print('X&Y shape of testing data :' , x_val.shape, 'and', y_val.shape, cat_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91 classes for training and 40  classes for testing\n",
            "X&Y shape of training data : (910, 3, 100, 100) and (910,) (91, 10)\n",
            "X&Y shape of testing data : (400, 3, 100, 100) and (400,) (40, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuACgkS4YlhM"
      },
      "source": [
        "## Generating Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k-slYI3Yo2D"
      },
      "source": [
        "def get_batch(batch_size=64):\n",
        "    \n",
        "    temp_x = x_train\n",
        "    temp_cat_list = cat_train\n",
        "    start=0\n",
        "    end=train_size\n",
        "    batch_x=[]\n",
        "        \n",
        "    batch_y = np.zeros(batch_size)\n",
        "    batch_y[int(batch_size/2):] = 1\n",
        "    np.random.shuffle(batch_y)\n",
        "    \n",
        "    class_list = np.random.randint(start, end, batch_size) \n",
        "    batch_x.append(np.zeros((batch_size, 3, 100, 100)))\n",
        "    batch_x.append(np.zeros((batch_size, 3, 100, 100)))\n",
        "\n",
        "    for i in range(0, batch_size):\n",
        "        batch_x[0][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
        "        #If train_y has 0 pick from the same class, else pick from any other class\n",
        "        if batch_y[i]==0:\n",
        "            batch_x[1][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
        "\n",
        "        else:\n",
        "            temp_list = np.append(temp_cat_list[:class_list[i]].flatten(), temp_cat_list[class_list[i]+1:].flatten())\n",
        "            batch_x[1][i] = temp_x[np.random.choice(temp_list)]\n",
        "            \n",
        "    return(batch_x, batch_y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5gplqrZY7FT"
      },
      "source": [
        "## Twin Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcnSmw5aY9n1"
      },
      "source": [
        "#Building a sequential model\n",
        "class CnnNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CnnNetwork, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(3, 64, 10)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 7)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(256 * 4, 4096)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "class TwinNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwinNetwork, self).__init__()\n",
        "        self.cnn = CnnNetwork()\n",
        "        self.fc1 = nn.Linear(4096, 1)\n",
        "\n",
        "    def forward(self, left, right):\n",
        "        x = self.cnn(left)\n",
        "        y = self.cnn(right)\n",
        "        diff = torch.abs(x - y)\n",
        "        z = F.sigmoid(self.fc1(diff))\n",
        "        return z\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEN8hj5IeDgr"
      },
      "source": [
        "## N-way one-shot Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb55CMwyeJha"
      },
      "source": [
        "def nway_one_shot(n_way, n_val):\n",
        "    \n",
        "    temp_x = x_val\n",
        "    temp_cat_list = cat_test\n",
        "    batch_x=[]\n",
        "    x_0_choice=[]\n",
        "    n_correct = 0\n",
        "   \n",
        "    class_list = np.random.randint(train_size+1, len(cat_list)-1, n_val)\n",
        "\n",
        "    for i in class_list:  \n",
        "        j = np.random.choice(cat_list[i])\n",
        "        temp=[]\n",
        "        temp.append(np.zeros((n_way, 3, 100, 100)))\n",
        "        temp.append(np.zeros((n_way, 3, 100, 100)))\n",
        "        for k in range(0, n_way):\n",
        "            temp[0][k] = x[j]\n",
        "            # 2 is arbitrary here, as 0 is the default number when all numbers\n",
        "            # are equal, which leads to wrong conclusions.\n",
        "            if k==2:\n",
        "                temp[1][k] = x[np.random.choice(cat_list[i])]\n",
        "            else:\n",
        "                temp[1][k] = x[np.random.choice(np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten()))]\n",
        "\n",
        "        result = twin_net(torch.Tensor(temp[0]).cuda(), torch.Tensor(temp[1]).cuda())\n",
        "        result = result.flatten().tolist()\n",
        "        result_index = result.index(min(result))\n",
        "        if result_index == 2:\n",
        "            n_correct = n_correct + 1\n",
        "    print(n_correct, \"correctly classified among\", n_val)\n",
        "    accuracy = (n_correct*100)/n_val\n",
        "    return accuracy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHZfladnDF1"
      },
      "source": [
        "# Tools to display batch data graphically\n",
        "def display_batch(batch_x, batch_y, batch_size=64):\n",
        "  num = int(batch_size ** 0.5)\n",
        "  combined_left = np.zeros((num*100, num*100, 3))\n",
        "  combined_right = np.zeros((num*100, num*100, 3))\n",
        "  count = 0\n",
        "  for i in range(num):\n",
        "    for j in range(num):\n",
        "      left_image = batch_x[0][count].transpose(1, 2, 0)\n",
        "      right_image = batch_x[1][count].transpose(1, 2, 0)\n",
        "      combined_left[i*100:(i+1)*100, j*100:(j+1)*100, :] = left_image\n",
        "      combined_right[i*100:(i+1)*100, j*100:(j+1)*100, :] = right_image\n",
        "      count += 1\n",
        "  plt.imshow(combined_left)\n",
        "  plt.show()\n",
        "  plt.imshow(combined_right)\n",
        "  plt.show()\n",
        "  print(\"batch_y is\")\n",
        "  print(np.reshape(batch_y, (-1, num)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JvNW3l5eW5F"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kFcTUnGeYYF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "39712616-020b-47e6-8ba2-05014637efb3"
      },
      "source": [
        "# We started learning_rate at 0.0006, but it was too coarse.\n",
        "learning_rate = 0.0001\n",
        "# twin_net = TwinNetwork().cuda()\n",
        "optimizer = torch.optim.Adam(twin_net.parameters(), lr=learning_rate)\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "epochs = 30000\n",
        "n_way = 20\n",
        "n_val = 100\n",
        "batch_size = 64\n",
        "\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "for epoch in range(epochs):\n",
        "    batch_x, batch_y = get_batch(batch_size)\n",
        "    # display_batch(batch_x, batch_y)\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    twin_outputs = twin_net(torch.Tensor(batch_x[0]).cuda(), torch.Tensor(batch_x[1]).cuda())\n",
        "    outputs = loss(twin_outputs, torch.Tensor(batch_y).reshape(64, 1).cuda())\n",
        "    outputs.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print('Epoch:', epoch, ', Loss:',outputs)\n",
        "    loss_list.append(outputs.item())\n",
        "    # print statistics\n",
        "    if epoch % 250 == 0:\n",
        "        print(\"=============================================\")\n",
        "        accuracy = nway_one_shot(n_way, n_val)\n",
        "        accuracy_list.append((epoch, accuracy))\n",
        "        print('Accuracy as of', epoch, 'epochs:', accuracy)\n",
        "        print('Epoch:', epoch, ', Loss:',np.mean(loss_list[-250:]))\n",
        "        print(\"=============================================\")\n",
        "        if(accuracy>90):\n",
        "            print(\"Achieved more than 90% Accuracy\")\n",
        "            break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-226dc717a6cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# twin_net = TwinNetwork().cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwin_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'twin_net' is not defined"
          ]
        }
      ]
    }
  ]
}